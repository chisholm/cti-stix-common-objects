{
    "type": "bundle",
    "id": "bundle--23b8b03f-0fca-4b93-b96e-efbb3c909a51",
    "objects": [
        {
            "type": "vulnerability",
            "spec_version": "2.1",
            "id": "vulnerability--79d8e8e1-1efe-47c6-984c-3a917040e9b4",
            "created_by_ref": "identity--8ce3f695-d5a4-4dc8-9e93-a65af453a31a",
            "created": "2025-05-21T02:01:07.271113Z",
            "modified": "2025-05-21T02:01:07.271113Z",
            "name": "CVE-2025-37920",
            "description": "In the Linux kernel, the following vulnerability has been resolved:\n\nxsk: Fix race condition in AF_XDP generic RX path\n\nMove rx_lock from xsk_socket to xsk_buff_pool.\nFix synchronization for shared umem mode in\ngeneric RX path where multiple sockets share\nsingle xsk_buff_pool.\n\nRX queue is exclusive to xsk_socket, while FILL\nqueue can be shared between multiple sockets.\nThis could result in race condition where two\nCPU cores access RX path of two different sockets\nsharing the same umem.\n\nProtect both queues by acquiring spinlock in shared\nxsk_buff_pool.\n\nLock contention may be minimized in the future by some\nper-thread FQ buffering.\n\nIt's safe and necessary to move spin_lock_bh(rx_lock)\nafter xsk_rcv_check():\n* xs->pool and spinlock_init is synchronized by\n  xsk_bind() -> xsk_is_bound() memory barriers.\n* xsk_rcv_check() may return true at the moment\n  of xsk_release() or xsk_unbind_dev(),\n  however this will not cause any data races or\n  race conditions. xsk_unbind_dev() removes xdp\n  socket from all maps and waits for completion\n  of all outstanding rx operations. Packets in\n  RX path will either complete safely or drop.",
            "external_references": [
                {
                    "source_name": "cve",
                    "external_id": "CVE-2025-37920"
                }
            ]
        }
    ]
}